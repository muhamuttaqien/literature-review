{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6e43208-e490-4703-8038-4e11ff0d5e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 12:51:35.872058: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-18 12:51:35.873229: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-18 12:51:35.895004: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-18 12:51:35.895735: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-18 12:51:36.295318: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b1d902-160f-4299-bb71-3172e23fdf4f",
   "metadata": {},
   "source": [
    "## Encoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea6c0b63-31ff-4d2f-8644-0647d0857818",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        # Define the layers for the encoder\n",
    "        self.flatten = layers.Flatten()  # Flatten the image input\n",
    "        self.dense1 = layers.Dense(512, activation='relu')  # First dense layer\n",
    "        self.dense2 = layers.Dense(256, activation='relu')  # Second dense layer\n",
    "        self.z_mean = layers.Dense(latent_dim)  # Mean of the latent distribution\n",
    "        self.z_log_var = layers.Dense(latent_dim)  # Log variance of the latent distribution\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, label = inputs  # Inputs: (image, label)\n",
    "        label = tf.one_hot(label, depth=10)  # One-hot encode the labels\n",
    "        x = tf.concat([x, label], axis=-1)  # Concatenate label with the image\n",
    "        x = self.flatten(x)  # Flatten the image into a 1D vector\n",
    "        x = self.dense1(x)  # Pass through the first dense layer\n",
    "        x = self.dense2(x)  # Pass through the second dense layer\n",
    "        z_mean = self.z_mean(x)  # Mean of the latent space\n",
    "        z_log_var = self.z_log_var(x)  # Log variance of the latent space\n",
    "        return z_mean, z_log_var\n",
    "\n",
    "# Reparameterization trick (sampling from the latent space)\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = tf.random.normal(tf.shape(z_mean))  # Sample from a normal distribution\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon  # Reparameterization trick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfbfbdd-2cbf-40eb-afb4-76f8fd77253e",
   "metadata": {},
   "source": [
    "## Decoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b463fc-a646-458f-bca1-80be70080fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        # Define the layers for the decoder\n",
    "        self.dense1 = layers.Dense(256, activation='relu')  # First dense layer\n",
    "        self.dense2 = layers.Dense(512, activation='relu')  # Second dense layer\n",
    "        self.output_layer = layers.Dense(28 * 28, activation='sigmoid')  # Output layer to reconstruct the image\n",
    "\n",
    "    def call(self, z):\n",
    "        x = self.dense1(z)  # Pass through the first dense layer\n",
    "        x = self.dense2(x)  # Pass through the second dense layer\n",
    "        x = self.output_layer(x)  # Reconstruct the image\n",
    "        return tf.reshape(x, (-1, 28, 28, 1))  # Reshape back to image shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9b1c6c-2697-4e24-9f95-410042c91f38",
   "metadata": {},
   "source": [
    "## CVAE class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c33e64a-87a0-4705-a4df-0e07ae75ea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.decoder = Decoder(latent_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, label = inputs  # Inputs: (image, label)\n",
    "        z_mean, z_log_var = self.encoder([x, label])  # Get mean and log variance from the encoder\n",
    "        z = sampling([z_mean, z_log_var])  # Sample from the latent space using the reparameterization trick\n",
    "        reconstructed = self.decoder(z)  # Reconstruct the image using the decoder\n",
    "        return reconstructed, z_mean, z_log_var\n",
    "\n",
    "# Loss function: Reconstruction loss + KL divergence\n",
    "def compute_loss(x, reconstructed, z_mean, z_log_var):\n",
    "    # Binary cross-entropy loss for image reconstruction\n",
    "    cross_entropy = tf.reduce_mean(tf.reduce_sum(\n",
    "        tf.keras.losses.binary_crossentropy(x, reconstructed), axis=[1, 2, 3]\n",
    "    ))\n",
    "    \n",
    "    # KL divergence between the learned distribution and the prior\n",
    "    kl_divergence = -0.5 * tf.reduce_mean(\n",
    "        tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)\n",
    "    )\n",
    "    \n",
    "    return cross_entropy + kl_divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02a22dc-ac95-41f1-9b37-f0f4aace5d98",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (muhammad-ra)",
   "language": "python",
   "name": "muhammad-ra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
