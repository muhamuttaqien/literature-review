{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6e43208-e490-4703-8038-4e11ff0d5e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b1d902-160f-4299-bb71-3172e23fdf4f",
   "metadata": {},
   "source": [
    "## Encoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea6c0b63-31ff-4d2f-8644-0647d0857818",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        # Define the layers for the encoder\n",
    "        self.flatten = nn.Flatten()  # Flatten the image input\n",
    "        self.dense1 = nn.Linear(28 * 28 + 10, 512)  # First dense layer\n",
    "        self.dense2 = nn.Linear(512, 256)  # Second dense layer\n",
    "        self.z_mean = nn.Linear(256, latent_dim)  # Mean of the latent distribution\n",
    "        self.z_log_var = nn.Linear(256, latent_dim)  # Log variance of the latent distribution\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        label = F.one_hot(label, num_classes=10).float()  # One-hot encode the labels\n",
    "        x = torch.cat([x.view(x.size(0), -1), label], dim=-1)  # Concatenate label with the image\n",
    "        x = F.relu(self.dense1(x))  # Pass through the first dense layer\n",
    "        x = F.relu(self.dense2(x))  # Pass through the second dense layer\n",
    "        z_mean = self.z_mean(x)  # Mean of the latent space\n",
    "        z_log_var = self.z_log_var(x)  # Log variance of the latent space\n",
    "        \n",
    "        return z_mean, z_log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfbfbdd-2cbf-40eb-afb4-76f8fd77253e",
   "metadata": {},
   "source": [
    "## Decoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b463fc-a646-458f-bca1-80be70080fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        # Define the layers for the decoder\n",
    "        self.dense1 = nn.Linear(latent_dim, 256)  # First dense layer\n",
    "        self.dense2 = nn.Linear(256, 512)  # Second dense layer\n",
    "        self.output_layer = nn.Linear(512, 28 * 28)  # Output layer to reconstruct the image\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = F.relu(self.dense1(z))  # Pass through the first dense layer\n",
    "        x = F.relu(self.dense2(x))  # Pass through the second dense layer\n",
    "        x = torch.sigmoid(self.output_layer(x))  # Reconstruct the image\n",
    "        return x.view(-1, 1, 28, 28)  # Reshape back to image shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9b1c6c-2697-4e24-9f95-410042c91f38",
   "metadata": {},
   "source": [
    "## CVAE class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b599aea3-454e-4bd6-a6a9-40b294bdf460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparameterization trick (sampling from the latent space)\n",
    "def sampling(z_mean, z_log_var):\n",
    "    epsilon = torch.randn_like(z_mean)  # Sample from a normal distribution\n",
    "    return z_mean + torch.exp(0.5 * z_log_var) * epsilon  # Reparameterization trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c33e64a-87a0-4705-a4df-0e07ae75ea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.decoder = Decoder(latent_dim)\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        z_mean, z_log_var = self.encoder(x, label)  # Get mean and log variance from the encoder\n",
    "        z = sampling(z_mean, z_log_var)  # Sample from the latent space using the reparameterization trick\n",
    "        reconstructed = self.decoder(z)  # Reconstruct the image using the decoder\n",
    "        return reconstructed, z_mean, z_log_var\n",
    "\n",
    "# Loss function: Reconstruction loss + KL divergence\n",
    "def compute_loss(x, reconstructed, z_mean, z_log_var):\n",
    "    # Binary cross-entropy loss for image reconstruction\n",
    "    BCE = F.binary_cross_entropy(reconstructed, x, reduction='sum')\n",
    "    \n",
    "    # KL divergence between the learned distribution and the prior\n",
    "    KL = -0.5 * torch.sum(1 + z_log_var - z_mean.pow(2) - z_log_var.exp())\n",
    "    \n",
    "    return BCE + KL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02a22dc-ac95-41f1-9b37-f0f4aace5d98",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (muhammad-ra)",
   "language": "python",
   "name": "muhammad-ra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
